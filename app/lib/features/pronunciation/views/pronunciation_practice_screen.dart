import 'dart:async';
import 'dart:io';
import 'package:flutter/material.dart';
import 'package:go_router/go_router.dart';
import 'package:record/record.dart';
import 'package:path_provider/path_provider.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:audioplayers/audioplayers.dart';
import '../../../core/models/deck.dart';
import '../../../core/models/vocabulary.dart';
import '../../../core/models/pronunciation_result.dart';
import '../../../core/api/api_client.dart';
import '../../decks/services/vocabulary_service.dart';
import '../services/pronunciation_service.dart';
import '../services/voice_coach_service.dart';
import '../widgets/pronunciation_app_bar.dart';
import '../widgets/pronunciation_empty_state.dart';
import '../widgets/pronunciation_navigation_bar.dart';
import '../widgets/pronunciation_practice_body.dart';
import '../widgets/pronunciation_details_bottom_sheet.dart';
import '../utils/wav_info_reader.dart';

class PronunciationPracticeScreen extends StatefulWidget {
  final Deck deck;

  const PronunciationPracticeScreen({
    super.key,
    required this.deck,
  });

  @override
  State<PronunciationPracticeScreen> createState() =>
      _PronunciationPracticeScreenState();
}

class _PronunciationPracticeScreenState
    extends State<PronunciationPracticeScreen> {
  final VocabularyService _vocabularyService = VocabularyService();
  final AudioRecorder _recorder = AudioRecorder();
  late final PronunciationService _pronunciationService;
  late final VoiceCoachService _voiceCoachService;
  final AudioPlayer _audioPlayer = AudioPlayer();
  bool _isPlayingVoiceCoach = false;
  bool _isLoadingAudio = false;

  List<Vocabulary> _vocabularies = [];
  int _currentIndex = 0;
  bool _isLoading = true;
  bool _isRecording = false;
  bool _isEvaluating = false;
  bool _hasResult = false;
  PronunciationResult? _result;
  bool _showConfetti = false;
  Timer? _confettiTimer;
  int? _recordStartedAtMs;
  StreamSubscription<Amplitude>? _amplitudeSubscription;
  int? _lastSoundDetectedAtMs;
  bool _isAutoStopping = false; // Flag to prevent multiple auto-stop calls
  double? _peakAmplitude; // Má»©c amplitude cao nháº¥t Ä‘Ã£ phÃ¡t hiá»‡n
  static const double _absoluteSilenceThreshold =
      -50.0; // NgÆ°á»¡ng tuyá»‡t Ä‘á»‘i (dB)
  static const double _relativeSilenceDropDb =
      15.0; // Coi lÃ  silence náº¿u amplitude giáº£m Ã­t nháº¥t 15 dB so vá»›i peak
  static const double _minPeakAmplitude =
      -35.0; // Má»©c amplitude tá»‘i thiá»ƒu Ä‘á»ƒ coi lÃ  cÃ³ Ã¢m thanh thá»±c sá»±
  static const int _silenceDurationMs =
      1000; // 2 seconds of silence to auto-stop
  static const int _minRecordingDurationMs =
      1000; // Minimum 1 second before auto-stop

  @override
  void initState() {
    super.initState();
    const apiBaseUrl = String.fromEnvironment(
      'API_BASE_URL',
      defaultValue: 'http://192.168.88.209:3000',
    );
    final apiClient = ApiClient(apiBaseUrl);
    _pronunciationService = PronunciationService(apiClient);
    _voiceCoachService = VoiceCoachService(apiClient: apiClient);
    _initializeRecorder();
    _loadVocabularies();
    _setupAudioPlayer();
  }

  void _setupAudioPlayer() {
    _audioPlayer.onPlayerStateChanged.listen((state) {
      if (mounted) {
        setState(() {
          _isPlayingVoiceCoach = state == PlayerState.playing;
        });
      }
    });
  }

  @override
  void dispose() {
    _amplitudeSubscription?.cancel();
    _recorder.dispose();
    _confettiTimer?.cancel();
    _audioPlayer.dispose();
    super.dispose();
  }

  Future<void> _initializeRecorder() async {
    try {
      final status = await Permission.microphone.request();
      if (!status.isGranted) {
        debugPrint('[Pronun] Microphone permission denied');
        return;
      }

      if (await _recorder.hasPermission()) {
        debugPrint('[Pronun] Recorder initialized');
      } else {
        debugPrint('[Pronun] Microphone permission not granted');
      }
    } catch (e) {
      debugPrint('[Pronun][ERROR] _initializeRecorder: $e');
    }
  }

  Future<void> _loadVocabularies() async {
    if (widget.deck.id == null) {
      setState(() => _isLoading = false);
      return;
    }

    try {
      final vocabularies =
          await _vocabularyService.getVocabulariesByDeckId(widget.deck.id!);
      setState(() {
        _vocabularies = vocabularies.where((v) => v.isActive).toList();
        _isLoading = false;
      });
    } catch (e) {
      if (mounted) {
        setState(() => _isLoading = false);
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(content: Text('Lá»—i khi táº£i tá»« vá»±ng: $e')),
        );
      }
    }
  }

  Vocabulary? get _currentVocabulary {
    if (_currentIndex < 0 || _currentIndex >= _vocabularies.length) {
      return null;
    }
    return _vocabularies[_currentIndex];
  }

  bool get _isHighScore => _hasResult && ((_result?.overall ?? 0) >= 80);
  bool get _isLowScore => _hasResult && ((_result?.overall ?? 0) < 60);

  Future<void> _startRecording() async {
    try {
      // Kiá»ƒm tra permission
      if (!await _recorder.hasPermission()) {
        final status = await Permission.microphone.request();
        if (!status.isGranted) {
          if (mounted) {
            ScaffoldMessenger.of(context).showSnackBar(
              const SnackBar(content: Text('Cáº§n quyá»n ghi Ã¢m')),
            );
          }
          return;
        }
      }

      // Kiá»ƒm tra xem recorder cÃ³ Ä‘ang recording khÃ´ng
      if (await _recorder.isRecording()) {
        debugPrint('[Pronun] Already recording, stopping first');
        await _recorder.stop();
        await Future.delayed(const Duration(milliseconds: 100));
      }

      _cancelConfetti();

      final dir = await getApplicationDocumentsDirectory();
      final path =
          '${dir.path}/rec_${DateTime.now().millisecondsSinceEpoch}.wav';

      // Cáº¥u hÃ¬nh Ä‘á»ƒ ghi WAV 16kHz mono PCM
      const config = RecordConfig(
        encoder: AudioEncoder.wav,
        sampleRate: 16000,
        numChannels: 1,
      );

      debugPrint('[Pronun] Starting recorder with config: WAV 16kHz mono');
      await _recorder.start(config, path: path);

      final nowMs = DateTime.now().millisecondsSinceEpoch;
      setState(() {
        _isRecording = true;
        _hasResult = false;
        _result = null;
        _recordStartedAtMs = nowMs;
        _lastSoundDetectedAtMs = nowMs;
        _isAutoStopping = false;
      });

      // Báº¯t Ä‘áº§u theo dÃµi amplitude Ä‘á»ƒ phÃ¡t hiá»‡n silence
      _startAmplitudeMonitoring();

      debugPrint('[Pronun] Recording started: WAV 16kHz mono PCM at $path');
    } catch (e) {
      debugPrint('[Pronun][ERROR] _startRecording: $e');
      if (mounted) {
        String errorMessage = 'Lá»—i khi báº¯t Ä‘áº§u ghi Ã¢m';
        if (e.toString().contains('MissingPluginException')) {
          errorMessage = 'Plugin ghi Ã¢m chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o. Vui lÃ²ng:\n'
              '1. Dá»«ng app hoÃ n toÃ n\n'
              '2. Cháº¡y: flutter clean && flutter pub get\n'
              '3. Rebuild app (khÃ´ng dÃ¹ng hot reload)';
        } else {
          errorMessage = 'Lá»—i khi báº¯t Ä‘áº§u ghi Ã¢m: $e';
        }
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(
            content: Text(errorMessage),
            duration: const Duration(seconds: 5),
          ),
        );
      }
    }
  }

  void _startAmplitudeMonitoring() {
    _amplitudeSubscription?.cancel();
    _isAutoStopping = false;
    _peakAmplitude = null;
    _amplitudeSubscription = _recorder
        .onAmplitudeChanged(
      const Duration(milliseconds: 100),
    )
        .listen(
      (amplitude) {
        if (!_isRecording || _isAutoStopping) return;

        final nowMs = DateTime.now().millisecondsSinceEpoch;
        final currentAmplitude = amplitude.current;

        // Cáº­p nháº­t peak amplitude náº¿u cÃ³ Ã¢m thanh Ä‘á»§ lá»›n
        if (currentAmplitude > _minPeakAmplitude) {
          if (_peakAmplitude == null || currentAmplitude > _peakAmplitude!) {
            _peakAmplitude = currentAmplitude;
          }
        }

        // Kiá»ƒm tra xem cÃ³ pháº£i silence khÃ´ng
        final isSilence = _isSilence(currentAmplitude);

        if (!isSilence) {
          // CÃ³ Ã¢m thanh
          _lastSoundDetectedAtMs = nowMs;
          debugPrint(
              '[Pronun][AutoStop] Sound: ${currentAmplitude.toStringAsFixed(1)} dB (peak: ${_peakAmplitude?.toStringAsFixed(1) ?? "N/A"})');
        } else {
          // Im láº·ng - kiá»ƒm tra xem Ä‘Ã£ im láº·ng Ä‘á»§ lÃ¢u chÆ°a
          final silenceDuration = _lastSoundDetectedAtMs != null
              ? nowMs - _lastSoundDetectedAtMs!
              : 0;
          final recordingDuration =
              _recordStartedAtMs != null ? nowMs - _recordStartedAtMs! : 0;

          debugPrint(
              '[Pronun][AutoStop] Silence: ${currentAmplitude.toStringAsFixed(1)} dB (duration: ${silenceDuration}ms, peak: ${_peakAmplitude?.toStringAsFixed(1) ?? "N/A"})');

          // Chá»‰ auto-stop náº¿u:
          // 1. ÄÃ£ ghi Ã¢m Ã­t nháº¥t _minRecordingDurationMs
          // 2. ÄÃ£ im láº·ng Ã­t nháº¥t _silenceDurationMs
          // 3. ÄÃ£ cÃ³ peak amplitude (Ä‘Ã£ tá»«ng cÃ³ Ã¢m thanh thá»±c sá»±)
          // 4. ChÆ°a Ä‘ang trong quÃ¡ trÃ¬nh auto-stop
          if (recordingDuration >= _minRecordingDurationMs &&
              silenceDuration >= _silenceDurationMs &&
              _peakAmplitude != null &&
              !_isAutoStopping) {
            debugPrint(
                '[Pronun][AutoStop] Auto-stopping after ${silenceDuration}ms of silence');
            _isAutoStopping = true;
            _stopRecording();
          }
        }
      },
      onError: (error) {
        debugPrint(
            '[Pronun][AutoStop][ERROR] Amplitude monitoring error: $error');
      },
    );
  }

  bool _isSilence(double currentAmplitude) {
    // Kiá»ƒm tra ngÆ°á»¡ng tuyá»‡t Ä‘á»‘i
    if (currentAmplitude <= _absoluteSilenceThreshold) {
      return true;
    }

    // Kiá»ƒm tra ngÆ°á»¡ng tÆ°Æ¡ng Ä‘á»‘i (so vá»›i peak)
    // Náº¿u Ä‘Ã£ cÃ³ peak amplitude Ä‘á»§ lá»›n, coi lÃ  silence náº¿u amplitude giáº£m Ä‘Ã¡ng ká»ƒ
    if (_peakAmplitude != null && _peakAmplitude! > _minPeakAmplitude) {
      final amplitudeDrop = _peakAmplitude! - currentAmplitude;
      // Náº¿u amplitude giáº£m Ã­t nháº¥t _relativeSilenceDropDb so vá»›i peak
      if (amplitudeDrop >= _relativeSilenceDropDb) {
        return true;
      }
    }

    return false;
  }

  Future<void> _stopRecording() async {
    try {
      // Dá»«ng theo dÃµi amplitude
      _amplitudeSubscription?.cancel();
      _amplitudeSubscription = null;

      final nowMs = DateTime.now().millisecondsSinceEpoch;
      final startedMs = _recordStartedAtMs ?? nowMs;
      final durationMs = nowMs - startedMs;

      const minDurationMs = 700;
      if (durationMs < minDurationMs) {
        debugPrint('[Pronun] Stop ignored: too short (${durationMs}ms)');
        if (mounted) {
          ScaffoldMessenger.of(context).showSnackBar(
            const SnackBar(content: Text('Báº£n ghi quÃ¡ ngáº¯n, vui lÃ²ng thá»­ láº¡i')),
          );
        }
        setState(() {
          _isRecording = false;
          _recordStartedAtMs = null;
          _lastSoundDetectedAtMs = null;
          _isAutoStopping = false;
          _peakAmplitude = null;
        });
        return;
      }

      final path = await _recorder.stop();
      debugPrint('[Pronun] Stop recording. File: $path (~${durationMs}ms)');

      // Cho encoder/IO cÃ³ thá»i gian ghi ná»‘t vÃ  sá»­a header
      await Future.delayed(const Duration(milliseconds: 300));

      setState(() {
        _isRecording = false;
        _recordStartedAtMs = null;
        _lastSoundDetectedAtMs = null;
        _isAutoStopping = false;
        _peakAmplitude = null;
      });

      if (path == null) return;

      final file = File(path);

      // Retry Ä‘á»c info vÃ i láº§n Ä‘á»ƒ Ä‘áº£m báº£o header Ä‘Ã£ finalize
      const tries = 4;
      int attempt = 0;
      Map<String, dynamic>? info;
      while (attempt < tries) {
        info = await WavInfoReader.readWavInfo(file);
        final totalLen = info['totalLen'] as int? ?? 0;
        final payloadBytes = totalLen > 44 ? totalLen - 44 : 0;

        final dataSize = info['dataSize'] as int?;
        final durationMsFromPayload = info['durationMsFromPayload'] as int?;
        final durationMsFromData = info['durationMsFromData'] as int?;

        debugPrint('[Pronun] attempt#$attempt '
            'payloadBytes=$payloadBytes dataSize=$dataSize '
            'durPayload=${durationMsFromPayload}ms durData=${durationMsFromData}ms');

        if (payloadBytes > 0 || (dataSize != null && dataSize > 0)) break;

        await Future.delayed(const Duration(milliseconds: 120));
        attempt++;
      }

      final stat = await file.stat();
      final size = stat.size;
      debugPrint('[Pronun] Recorded file info: '
          'path=$path, size=${size} bytes, modified=${stat.modified.toIso8601String()}');

      if (size <= 44) {
        if (mounted) {
          ScaffoldMessenger.of(context).showSnackBar(
            const SnackBar(
              content: Text(
                'KhÃ´ng thu Ä‘Æ°á»£c Ã¢m thanh. Kiá»ƒm tra quyá»n micro hoáº·c thá»­ trÃªn thiáº¿t bá»‹ tháº­t.',
              ),
            ),
          );
        }
        try {
          await file.delete();
        } catch (_) {}
        return;
      }

      if (size < 2000) {
        if (mounted) {
          ScaffoldMessenger.of(context).showSnackBar(
            const SnackBar(
              content:
                  Text('Ã‚m thanh quÃ¡ ngáº¯n hoáº·c khÃ´ng há»£p lá»‡, vui lÃ²ng ghi láº¡i'),
            ),
          );
        }
        try {
          await file.delete();
        } catch (_) {}
        return;
      }

      await _evaluatePronunciation(file);
    } catch (e) {
      debugPrint('[Pronun][ERROR] _stopRecording: $e');
      if (mounted) {
        setState(() => _isRecording = false);
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(content: Text('Lá»—i khi dá»«ng ghi Ã¢m: $e')),
        );
      }
    }
  }

  Future<void> _handleVoiceCoach() async {
    final vocabulary = _currentVocabulary;
    if (vocabulary == null) return;

    // Náº¿u Ä‘ang phÃ¡t, dá»«ng láº¡i
    if (_isPlayingVoiceCoach) {
      await _audioPlayer.stop();
      return;
    }

    try {
      // Kiá»ƒm tra xem audio Ä‘Ã£ táº£i chÆ°a
      final audioPath = await _voiceCoachService.getAudioPath(vocabulary);

      if (audioPath != null && await File(audioPath).exists()) {
        // PhÃ¡t audio tá»« file Ä‘Ã£ lÆ°u
        await _audioPlayer.play(DeviceFileSource(audioPath));
      } else {
        // Náº¿u chÆ°a cÃ³ file, thá»­ táº£i hoáº·c dÃ¹ng TTS
        setState(() {
          _isLoadingAudio = true;
        });

        // Táº£i audio
        final loadedPath =
            await _voiceCoachService.loadVoiceCoachAudio(vocabulary);

        if (mounted) {
          setState(() {
            _isLoadingAudio = false;
          });
        }

        if (loadedPath != null && await File(loadedPath).exists()) {
          // PhÃ¡t audio tá»« file vá»«a táº£i
          await _audioPlayer.play(DeviceFileSource(loadedPath));
        } else {
          // Fallback: Sá»­ dá»¥ng TTS Ä‘á»ƒ phÃ¡t trá»±c tiáº¿p
          await _voiceCoachService.playVoiceCoach(vocabulary);
        }
      }
    } catch (e) {
      debugPrint('[VoiceCoach] Error playing audio: $e');
      if (mounted) {
        setState(() {
          _isLoadingAudio = false;
        });
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(
            content: Text('Lá»—i khi phÃ¡t audio: $e'),
            backgroundColor: Colors.red,
            duration: const Duration(seconds: 3),
          ),
        );
      }
    }
  }

  void _handleRepeat() {
    if (_isRecording || _isEvaluating) return;
    _cancelConfetti();
    setState(() {
      _hasResult = false;
      _result = null;
    });
  }

  Future<void> _evaluatePronunciation(File audioFile) async {
    final vocabulary = _currentVocabulary;
    if (vocabulary == null) return;

    setState(() {
      _isEvaluating = true;
    });

    try {
      final fileSize = await audioFile.length();
      final fileStat = await audioFile.stat();

      debugPrint('[Pronun] ========== Starting Evaluation ==========');
      debugPrint('[Pronun] Audio File: ${audioFile.path}');
      debugPrint(
          '[Pronun] File Size: ${fileSize} bytes (${(fileSize / 1024).toStringAsFixed(2)} KB)');
      debugPrint('[Pronun] Modified: ${fileStat.modified}');
      debugPrint('[Pronun] Reference Text: "${vocabulary.front}"');
      debugPrint('[Pronun] Language Code: en-US');
      debugPrint('[Pronun] Sending request to API...');

      final result = await _pronunciationService.assessPronunciation(
        audioFile: audioFile,
        referenceText: vocabulary.front,
        languageCode: 'en-US',
      );

      debugPrint('[Pronun] Received response from API');

      final isHighScore = result.overall >= 80;

      setState(() {
        _result = result;
        _hasResult = true;
        _isEvaluating = false;
        _showConfetti = isHighScore;
      });

      if (isHighScore) {
        _startConfettiCountdown();
      } else {
        _confettiTimer?.cancel();
        _confettiTimer = null;
      }

      // Log tá»•ng quan
      debugPrint('[Pronun] ========== Evaluation Results ==========');
      debugPrint(
          '[Pronun] Overall Score: ${result.overall.toStringAsFixed(1)}/100');
      debugPrint(
          '[Pronun] Accuracy: ${result.accuracy.toStringAsFixed(1)}/100');
      debugPrint('[Pronun] Fluency: ${result.fluency.toStringAsFixed(1)}/100');
      debugPrint(
          '[Pronun] Completeness: ${result.completeness.toStringAsFixed(1)}/100');
      debugPrint(
          '[Pronun] Total Words: ${result.words.length}, Total Phonemes: ${result.phonemes.length}');
      debugPrint('[Pronun] =========================================');

      // Log chi tiáº¿t tá»«ng tá»« vÃ  Ã¢m vá»‹
      for (int wi = 0; wi < result.words.length; wi++) {
        final word = result.words[wi];
        final wordPhonemes =
            result.phonemes.where((p) => p.wordIndex == wi).toList();

        debugPrint('[Pronun] --- Word $wi: "${word.text}" ---');
        debugPrint('[Pronun]   Score: ${word.score.toStringAsFixed(1)}/100');
        debugPrint(
            '[Pronun]   Timing: ${word.start}ms - ${word.end}ms (duration: ${word.end - word.start}ms)');
        debugPrint('[Pronun]   Phonemes (${wordPhonemes.length}):');

        for (int pi = 0; pi < wordPhonemes.length; pi++) {
          final phoneme = wordPhonemes[pi];
          final scoreColor = phoneme.score >= 80
              ? 'ðŸŸ¢'
              : phoneme.score >= 60
                  ? 'ðŸŸ¡'
                  : 'ðŸ”´';

          debugPrint('[Pronun]     [$pi] $scoreColor ${phoneme.p}: '
              '${phoneme.score.toStringAsFixed(1)}/100 '
              '[${phoneme.start}ms - ${phoneme.end}ms, '
              'duration: ${phoneme.end - phoneme.start}ms]');
        }
        debugPrint('[Pronun] ');
      }

      debugPrint('[Pronun] =========================================');
    } catch (e) {
      debugPrint('[Pronun][ERROR] _evaluatePronunciation: $e');
      if (mounted) {
        setState(() => _isEvaluating = false);
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(content: Text('Lá»—i khi Ä‘Ã¡nh giÃ¡: $e')),
        );
      }
    }
  }

  Color _getScoreColor(double score) {
    if (score >= 80) return Colors.green;
    if (score >= 60) return Colors.orange;
    return Colors.red;
  }

  void _nextVocabulary() {
    if (_currentIndex < _vocabularies.length - 1) {
      _cancelConfetti();
      setState(() {
        _currentIndex++;
        _hasResult = false;
        _result = null;
      });
    }
  }

  void _previousVocabulary() {
    if (_currentIndex > 0) {
      _cancelConfetti();
      setState(() {
        _currentIndex--;
        _hasResult = false;
        _result = null;
      });
    }
  }

  void _startConfettiCountdown() {
    _confettiTimer?.cancel();
    _confettiTimer = Timer(const Duration(seconds: 8), () {
      if (mounted) {
        setState(() => _showConfetti = false);
      }
    });
  }

  void _cancelConfetti() {
    _confettiTimer?.cancel();
    _confettiTimer = null;
    if (_showConfetti) {
      setState(() => _showConfetti = false);
    }
  }

  @override
  Widget build(BuildContext context) {
    final vocabulary = _currentVocabulary;
    final hasEvaluated = _hasResult && _result != null;

    return Scaffold(
      backgroundColor: const Color(0xFFF1F3F8),
      appBar: PronunciationAppBar(
        currentExercise: _currentIndex + 1,
        deckName: widget.deck.name,
        onBack: () => context.pop(),
        onDownloadTap: () {
          context.push('/pronunciation/voice-coach-loading',
              extra: widget.deck);
        },
      ),
      body: _isLoading
          ? const Center(child: CircularProgressIndicator())
          : _vocabularies.isEmpty
              ? const PronunciationEmptyState()
              : (vocabulary == null
                  ? const SizedBox()
                  : PronunciationPracticeBody(
                      vocabulary: vocabulary,
                      currentExercise: _currentIndex + 1,
                      totalExercises: _vocabularies.length,
                      isHighScore: _isHighScore,
                      isLowScore: _isLowScore,
                      hasResult: hasEvaluated,
                      statusMessage: _statusMessage(),
                      isRecording: _isRecording,
                      isEvaluating: _isEvaluating,
                      showConfetti: _showConfetti,
                      isLoadingAudio: _isLoadingAudio,
                      onVoiceCoach: _handleVoiceCoach,
                      onRepeat: _handleRepeat,
                      onStartRecording: _startRecording,
                      onStopRecording: _stopRecording,
                      onShowDetails: _showDetailsBottomSheet,
                    )),
      bottomNavigationBar: _isLoading || _vocabularies.isEmpty
          ? null
          : SafeArea(
              top: false,
              child: Padding(
                padding:
                    const EdgeInsets.symmetric(horizontal: 24, vertical: 12),
                child: PronunciationNavigationBar(
                  hasPrevious: _currentIndex > 0,
                  hasNext: _currentIndex < _vocabularies.length - 1,
                  onPrevious: _previousVocabulary,
                  onNext: _nextVocabulary,
                ),
              ),
            ),
    );
  }

  void _showDetailsBottomSheet() {
    if (!_hasResult || _result == null) return;
    PronunciationDetailsBottomSheet.show(
      context,
      result: _result!,
      currentExerciseIndex: _currentIndex,
      colorResolver: _getScoreColor,
      isPhonemeCorrect: _isPhonemeCorrect,
    );
  }

  String _statusMessage() {
    if (_isEvaluating) return 'Äang cháº¥m Ä‘iá»ƒm...';
    if (_isRecording) return 'Äang nghe báº¡n nÃ³i';
    if (_hasResult && _result != null) {
      if (_result!.overall >= 80) return 'Tuyá»‡t vá»i!';
      if (_result!.overall >= 60) return 'Gáº§n Ä‘áº¿n rá»“i!';
      return 'Thá»­ láº¡i!';
    }
    return 'Báº¯t Ä‘áº§u nÃ³i';
  }

  bool _isPhonemeCorrect(double score) => score >= 70;
}
